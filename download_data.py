#!/usr/bin/env python3
"""
TÃ©lÃ©charge et prÃ©pare le dataset Sentiment140 pour le TP
"""

import os
import sys
import pandas as pd
import urllib.request
import random

def download_sentiment140_sample():
    """TÃ©lÃ©charge un Ã©chantillon du dataset Sentiment140"""
    
    print("ğŸ“¥ TÃ©lÃ©chargement du dataset Sentiment140 (Ã©chantillon)...")
    
    # URL publique d'un Ã©chantillon de Sentiment140
    urls = [
        "https://raw.githubusercontent.com/vineetdhanawat/twitter-sentiment-analysis/master/datasets/Sentiment%20Analysis%20Dataset.csv",
        "https://raw.githubusercontent.com/Vasistareddy/sentiment_analysis/master/data/tweet.csv"
    ]
    
    for url in urls:
        try:
            # TÃ©lÃ©charger le fichier
            urllib.request.urlretrieve(url, "data/temp_tweets.csv")
            
            # Charger et nettoyer
            df = pd.read_csv("data/temp_tweets.csv", error_bad_lines=False, nrows=50000)
            
            # Identifier la colonne de texte
            text_col = None
            for col in ['text', 'tweet', 'SentimentText', 'Text']:
                if col in df.columns:
                    text_col = col
                    break
            
            if text_col:
                df = df[[text_col]].rename(columns={text_col: 'text'})
                df = df[df['text'].notna()]
                df = df[df['text'].str.len() > 30]
                
                if len(df) > 100:
                    print(f"âœ… {len(df)} tweets tÃ©lÃ©chargÃ©s avec succÃ¨s")
                    return df
                    
        except Exception as e:
            print(f"âš ï¸  Ã‰chec avec {url}: {e}")
            continue
    
    # Si Ã©chec, gÃ©nÃ©rer des tweets
    print("âš ï¸  TÃ©lÃ©chargement Ã©chouÃ©, gÃ©nÃ©ration de tweets synthÃ©tiques...")
    return generate_fallback_tweets()

def generate_fallback_tweets():
    """GÃ©nÃ¨re des tweets synthÃ©tiques si le tÃ©lÃ©chargement Ã©choue"""
    
    templates = [
        "Just watched {} and it was {} ! ğŸ˜ #{} #movies",
        "Can't believe {} is happening {} ! This is {} ğŸ¤¯",
        "@{} Thanks for {} ! Really {} experience ğŸ™ #{}",
        "Working on {} today. {} is harder than expected ğŸ˜… #coding",
        "New {} just dropped! {} looks {} ğŸ”¥ Check it out: http://bit.ly/{}",
        "Why is {} so {} ? Someone explain {} to me please ğŸ¤”",
        "{} weather today! Perfect for {} â˜€ï¸ #{} #{}",
        "Finally finished {} ! Took {} hours but worth it ğŸ’ª #{}",
        "RT @{}: {} is the future of {} ! {} #innovation",
        "Unpopular opinion: {} is overrated. {} is much better IMO ğŸ¤·"
    ]
    
    words = ['amazing', 'terrible', 'awesome', 'crazy', 'unbelievable', 'fantastic',
             'Python', 'coding', 'AI', 'machine learning', 'data science', 'web dev',
             'coffee', 'pizza', 'music', 'sports', 'gaming', 'travel', 'food',
             'happy', 'sad', 'excited', 'tired', 'motivated', 'inspired']
    
    tweets = []
    for _ in range(10000):
        template = random.choice(templates)
        count = template.count('{}')
        values = [random.choice(words) for _ in range(count)]
        tweet = template.format(*values)
        tweets.append(tweet)
    
    return pd.DataFrame({'text': tweets})

def prepare_datasets(df):
    """PrÃ©pare les datasets de diffÃ©rentes tailles"""
    
    print("\nğŸ“Š PrÃ©paration des datasets...")
    
    # Small (100 tweets)
    df_small = df.sample(n=min(100, len(df)), random_state=42)
    df_small.to_csv('data/tweets_small.csv', index=False)
    print(f"   âœ… data/tweets_small.csv : 100 tweets")
    
    # Medium (1000 tweets)
    n_medium = min(1000, len(df))
    df_medium = df.sample(n=n_medium, random_state=42)
    df_medium.to_csv('data/tweets_medium.csv', index=False)
    print(f"   âœ… data/tweets_medium.csv : {n_medium} tweets")
    
    # Large (10000 tweets)
    n_large = min(10000, len(df))
    df_large = df.sample(n=n_large, random_state=42)
    df_large.to_csv('data/tweets_large.csv', index=False)
    print(f"   âœ… data/tweets_large.csv : {n_large} tweets")
    
    # Statistiques
    print("\nğŸ“ˆ Statistiques des tweets:")
    lengths = df_small['text'].str.len()
    print(f"   â€¢ Longueur moyenne: {lengths.mean():.1f} caractÃ¨res")
    print(f"   â€¢ Min/Max: {lengths.min()}/{lengths.max()} caractÃ¨res")
    
    # Exemples
    print("\nğŸ“ Exemples de tweets:")
    for i, tweet in enumerate(df_small['text'].head(3), 1):
        print(f"\n   {i}. {tweet[:100]}{'...' if len(tweet) > 100 else ''}")

if __name__ == "__main__":
    random.seed(42)  # ReproductibilitÃ©
    
    # CrÃ©er le dossier data
    os.makedirs('data', exist_ok=True)
    
    # TÃ©lÃ©charger ou gÃ©nÃ©rer les donnÃ©es
    df = download_sentiment140_sample()
    
    # PrÃ©parer les datasets
    prepare_datasets(df)
    
    print("\nâœ… DonnÃ©es prÃªtes pour le TP!")
